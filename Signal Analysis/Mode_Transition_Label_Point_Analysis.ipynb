{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mode Transition Label Analysis.ipynb",
      "provenance": [],
      "mount_file_id": "1hzh5HLYNQZWnmkI9RN2Gce-2ND2ClZBU",
      "authorship_tag": "ABX9TyP/za9vDpNZym40Lxgp53YI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/inseungkang/HipExo_OfflineModeClassification/blob/master/Mode_Transition_Label_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66wY7Bn2s6pg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "import collections\n",
        "import statistics\n",
        "from os import path\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from joblib import Parallel, delayed\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQxhE9SNuO2G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#############################################################################\n",
        "def lda_parallel(combo):\n",
        "    testing_subject = combo[0]\n",
        "    window_size = combo[1]\n",
        "    transition_point = combo[2]\n",
        "    phase_number = combo[3]\n",
        "\n",
        "    fe_dir = \"/HDD/Inseung/Dropbox (GaTech)/ML/data/sensor_fusion/feature extraction data/\"\n",
        "\n",
        "    trial_pool = [1, 2, 3]\n",
        "    subject_pool = [6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 27 ,28]\n",
        "    del subject_pool[subject_pool.index(testing_subject)]\n",
        "\n",
        "    X_train = pd.DataFrame()\n",
        "    Y_train = pd.DataFrame()\n",
        "    gp_train = pd.DataFrame()\n",
        "    Y_test_result = []\n",
        "    Y_pred_result = []\n",
        "\n",
        "######### concat all the training data ##############\n",
        "    for trial in trial_pool:\n",
        "        for subject in subject_pool:\n",
        "            for mode in [\"RA2\", \"RA3\", \"RA4\", \"RA5\", \"RD2\", \"RD3\", \"RD4\", \"RD5\",\"SA1\", \"SA2\", \"SA3\", \"SA4\", \"SD1\", \"SD2\", \"SD3\", \"SD4\"]:\n",
        "                for starting_leg in [\"R\", \"L\"]:\n",
        "                    train_path = fe_dir+\"AB\"+str(subject)+\"_\"+str(mode)+\"_W\"+str(window_size)+\"_TP\"+str(int(transition_point*10))+\"_S2_\"+str(starting_leg)+str(trial)+\".csv\"\n",
        "\n",
        "                    if path.exists(train_path) == 1:\n",
        "                        for train_read_path in glob.glob(train_path):\n",
        "                            data = pd.read_csv(train_read_path, header=None)\n",
        "                            X = data.iloc[:, :-3]\n",
        "                            Y = data.iloc[:, -1]\n",
        "                            gp = data.iloc[:,-2]\n",
        "                            X_train = pd.concat([X_train, X], axis=0, ignore_index=True)\n",
        "                            Y_train = pd.concat([Y_train, Y], axis=0, ignore_index=True)\n",
        "                            gp_train = pd.concat([gp_train, gp], axis=0, ignore_index=True)\n",
        "\n",
        "            train_path = fe_dir+\"AB\"+str(subject)+\"_LG_W\"+str(window_size)+\"_TP0_S2_R\"+str(trial)+\".csv\"    \n",
        "            if path.exists(train_path) == 1:\n",
        "                for train_read_path in glob.glob(train_path):\n",
        "                    data = pd.read_csv(train_read_path, header=None)\n",
        "                    X = data.iloc[:, :-3]\n",
        "                    Y = data.iloc[:, -1]\n",
        "                    gp = data.iloc[:,-2]\n",
        "                    X_train = pd.concat([X_train, X], axis=0, ignore_index=True)\n",
        "                    Y_train = pd.concat([Y_train, Y], axis=0, ignore_index=True)\n",
        "                    gp_train = pd.concat([gp_train, gp], axis=0, ignore_index=True)\n",
        "\n",
        "    if phase_number == 1:\n",
        "######### training the unified model ##############\n",
        "        lda_model = LDA()\n",
        "        lda_model.fit(X_train, np.ravel(Y_train))\n",
        "        del [[X, Y, gp, X_train, Y_train, gp_train]]\n",
        "\n",
        "######### testing the unified model ##############\n",
        "        for mode in [\"RA2\", \"RA3\", \"RA4\", \"RA5\", \"RD2\", \"RD3\", \"RD4\", \"RD5\", \"SA1\", \"SA2\", \"SA3\", \"SA4\", \"SD1\", \"SD2\", \"SD3\", \"SD4\"]:\n",
        "            for starting_leg in [\"R\", \"L\"]:   \n",
        "                for trial in trial_pool: \n",
        "                    test_path = fe_dir+\"AB\"+str(testing_subject)+\"_\"+str(mode)+\"_W\"+str(window_size)+\"_TP\"+str(int(transition_point*10))+\"_S2_\"+str(starting_leg)+str(trial)+\".csv\"\n",
        "\n",
        "                    if path.exists(test_path) == 1:\n",
        "                        for test_read_path in glob.glob(test_path):\n",
        "                            data = pd.read_csv(test_read_path, header=None)\n",
        "                            X = data.iloc[:, :-3]\n",
        "                            Y = data.iloc[:, -1]\n",
        "                            Y_pred = lda_model.predict(X)\n",
        "                            Y_pred_result = np.concatenate((Y_pred_result, Y_pred))\n",
        "                            Y_test_result = np.concatenate((Y_test_result, Y))\n",
        "\n",
        "        for trial in trial_pool:\n",
        "            train_path = fe_dir+\"AB\"+str(testing_subject)+\"_LG_W\"+str(window_size)+\"_TP0_S2_R\"+str(trial)+\".csv\"\n",
        "\n",
        "            if path.exists(test_path) == 1:\n",
        "                for test_read_path in glob.glob(test_path):\n",
        "                    data = pd.read_csv(test_read_path, header=None)\n",
        "                    X = data.iloc[:, :-3]\n",
        "                    Y = data.iloc[:, -1]\n",
        "                    Y_pred = lda_model.predict(X)\n",
        "                    Y_pred_result = np.concatenate((Y_pred_result, Y_pred))\n",
        "                    Y_test_result = np.concatenate((Y_test_result, Y))\n",
        "                    del [[X, Y, Y_pred]]\n",
        "\n",
        "    else:\n",
        "######### training the phase dependent model ##############\n",
        "        gp_train = gp_train.values\n",
        "        gp_train[gp_train == 100] = 99.99\n",
        "        gp_train_idx = []\n",
        "        phase_model = []\n",
        "        phase_count = np.arange(phase_number)\n",
        "\n",
        "        for ii in phase_count:\n",
        "            gp_train_idx.append([jj for jj, phase in enumerate(gp_train) if phase >= 0 + (ii/phase_number)*100 and phase < ((ii+1)/phase_number)*100])\n",
        "\n",
        "        for ii in phase_count:\n",
        "            lda_model = LDA()\n",
        "            lda_model.fit(X_train.values[gp_train_idx[ii]], np.ravel(Y_train.values[gp_train_idx[ii]]))\n",
        "            phase_model.append(lda_model)\n",
        "\n",
        "        del [[X, Y, gp, X_train, Y_train, gp_train]]\n",
        "\n",
        "######### testing the phase dependent model ##############\n",
        "        for mode in [\"RA2\", \"RA3\", \"RA4\", \"RA5\", \"RD2\", \"RD3\", \"RD4\", \"RD5\", \"SA1\", \"SA2\", \"SA3\", \"SA4\", \"SD1\", \"SD2\", \"SD3\", \"SD4\"]:\n",
        "            for starting_leg in [\"R\", \"L\"]:   \n",
        "                for trial in trial_pool: \n",
        "                    test_path = fe_dir+\"AB\"+str(testing_subject)+\"_\"+str(mode)+\"_W\"+str(window_size)+\"_TP\"+str(int(transition_point*10))+\"_S2_\"+str(starting_leg)+str(trial)+\".csv\"\n",
        "\n",
        "                    if path.exists(test_path) == 1:\n",
        "                        for test_read_path in glob.glob(test_path):\n",
        "                            data = pd.read_csv(test_read_path, header=None)\n",
        "                            X = data.iloc[:, :-3]\n",
        "                            Y = data.iloc[:, -1]\n",
        "                            gp = data.iloc[:, -2].values\n",
        "                            gp[gp == 100] = 99.99\n",
        "\n",
        "                            for ii in range(len(Y)):\n",
        "                                for jj in phase_count:\n",
        "                                    if gp[ii] >= 0 + (jj/phase_number)*100 and gp[ii] < ((jj+1)/phase_number)*100:\n",
        "                                        Y_pred = phase_model[jj].predict(X.values[ii,:].reshape(1, -1))\n",
        "                                        Y_pred_result.append(Y_pred)                            \n",
        "                            Y_test_result = np.concatenate((Y_test_result, Y))\n",
        "\n",
        "\n",
        "        for trial in trial_pool:\n",
        "            train_path = fe_dir+\"AB\"+str(testing_subject)+\"_LG_W\"+str(window_size)+\"_TP0_S2_R\"+str(trial)+\".csv\"\n",
        "\n",
        "            if path.exists(test_path) == 1:\n",
        "                for test_read_path in glob.glob(test_path):\n",
        "                    data = pd.read_csv(test_read_path, header=None)\n",
        "                    X = data.iloc[:, :-3]\n",
        "                    Y = data.iloc[:, -1]\n",
        "                    gp = data.iloc[:, -2].values\n",
        "                    gp[gp == 100] = 99.99\n",
        "\n",
        "                    for ii in range(len(Y)):\n",
        "                        for jj in phase_count:\n",
        "                            if gp[ii] >= 0 + (jj/phase_number)*100 and gp[ii] < ((jj+1)/phase_number)*100:\n",
        "                                Y_pred = phase_model[jj].predict(X.values[ii,:].reshape(1, -1))\n",
        "                                Y_pred_result.append(Y_pred)                            \n",
        "                    Y_test_result = np.concatenate((Y_test_result, Y))\n",
        "                    del [[X, Y, gp, Y_pred]]\n",
        "\n",
        "    Y_test_result = np.ravel(Y_test_result)\n",
        "    Y_pred_result = np.ravel(Y_pred_result)\n",
        "    LDA_overall_accuracy = accuracy_score(Y_test_result, Y_pred_result)\n",
        "    print(\"subject = \"+str(testing_subject)+\" window size = \"+str(window_size)+\" phase number = \"+str(phase_number)+ \" Accuracy = \"+str(LDA_overall_accuracy))\n",
        "\n",
        "    base_path_dir = \"/HDD/Inseung/Dropbox (GaTech)/ML/data/sensor_fusion/Result/\"\n",
        "    text_file1 = base_path_dir + \"LDA_phase_result.txt\"\n",
        "\n",
        "    msg1 = ' '.join([str(testing_subject),str(window_size),str(transition_point),str(phase_number),str(LDA_overall_accuracy),\"\\n\"])\n",
        "    return text_file1, msg1\n",
        "\n",
        "run_combos = []\n",
        "for testing_subject in [6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 27 ,28]:\n",
        "    for window_size in [750]:\n",
        "        for transition_point in [0.2]:\n",
        "            for phase_number in [1, 2, 3, 4, 5, 6, 7, 8]:\n",
        "                run_combos.append([testing_subject, window_size, transition_point, phase_number])\n",
        "result = Parallel(n_jobs=-1)(delayed(lda_parallel)(combo) for combo in run_combos)\n",
        "for r in result:\n",
        "    with open(r[0],\"a+\") as f:\n",
        "        f.write(r[1])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}